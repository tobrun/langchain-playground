{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "Compared to chains, agents are more flexible, actions aren't hard coded. With Agents, a LLM is used as a reasoning engine to determine which actions to take and in which order.\n",
    "\n",
    "Some important keywords:\n",
    " - **AgentAction**: dataclass that is an action. Has a tool property and `tool_input``.\n",
    " - **AgentFinish**: dataclass that indicates the agent is done and will return to the user. Has `return_values`` dictionary. Most of the time, it will have 1 value for the key `output`\n",
    " - **intermediate_steps**: a list of AgentActions that are executed before the AgentFinish is returned to the user.\n",
    "\n",
    "\n",
    "## Agent\n",
    "\n",
    "Chain responsible for deciding what stept to take next:\n",
    "The inputs to this chain are:\n",
    "  - list of available tools\n",
    "  - user input\n",
    "  - any previously executed steps\n",
    "\n",
    "## Tools\n",
    "\n",
    "Tools are functions that an agent calls. There are 2 considirations:\n",
    " - Giving the agent access to the right tools\n",
    " - Describing the tools in a way that is helpful for the agent\n",
    "\n",
    "## Toolkits\n",
    "\n",
    "Set of tools an agent has access to, generally 3-5 tools in a toolkit.\n",
    "\n",
    "## AgentExecutor\n",
    "\n",
    "Runtime for an agent, this is what calls the agent and executes the actions it chooses.\n",
    "\n",
    "You do have other types of agent runtimes:\n",
    " - Plan-and-execute Agent\n",
    " - Baby AGI\n",
    " - Auto GPT\n",
    "\n",
    "\n",
    "## Building your own agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='get_word_length', tool_input={'word': 'educa'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'educa'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_word_length', 'arguments': '{\\n  \"word\": \"educa\"\\n}'}})])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the LLM to control the agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# define some tools\n",
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "tools = [get_word_length]\n",
    "\n",
    "# Now let us create the prompt. Because OpenAI Function Calling is finetuned for tool usage, \n",
    "# we hardly need any instructions on how to reason, or how to output format. \n",
    "# We will just have two input variables: input (for the user question) and agent_scratchpad (for any previous steps taken)\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are very powerful assistant, but bad at calculating lengths of words.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# How does the agent know what tools it can use? Those are passed in as a separate argument, \n",
    "# so we can bind those as keyword arguments to the LLM.\n",
    "\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "llm_with_tools = llm.bind(\n",
    "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
    ")\n",
    "\n",
    "# Putting those pieces together, we can now create the agent.\n",
    "# We import two util functions for formmating intermediate steps + converting the output to an agent finish\n",
    "\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "agent = {\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps'])\n",
    "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the agent to answer questions. Let us start with a simple one.\n",
    "\n",
    "agent.invoke({\n",
    "    \"input\": \"how many letters in the word educa?\",\n",
    "    \"intermediate_steps\": []\n",
    "})\n",
    "\n",
    "# We can see that it responds with an AgentAction to take (it's actually an AgentActionMessageLog \n",
    "# a subclass of AgentAction which also tracks the full message log)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_word_length {'word': 'educa'}\n",
      "There are 5 letters in the word \"educa\".\n"
     ]
    }
   ],
   "source": [
    "# So this is just the first step - now we need to write a runtime for this. \n",
    "# The simplest one is just one that continuously loops, calling the agent, \n",
    "# then taking the action, and repeating until an AgentFinish is returned.\n",
    "# Let's code that up below:\n",
    "\n",
    "from langchain.schema.agent import AgentFinish\n",
    "intermediate_steps = []\n",
    "while True:\n",
    "    output = agent.invoke({\n",
    "        \"input\": \"how many letters in the word educa?\",\n",
    "        \"intermediate_steps\": intermediate_steps\n",
    "    })\n",
    "    if isinstance(output, AgentFinish):\n",
    "        final_result = output.return_values[\"output\"]\n",
    "        break\n",
    "    else:\n",
    "        print(output.tool, output.tool_input)\n",
    "        tool = {\n",
    "            \"get_word_length\": get_word_length\n",
    "        }[output.tool]\n",
    "        observation = tool.run(output.tool_input)\n",
    "        intermediate_steps.append((output, observation))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThere are 5 letters in the word \"educa\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how many letters in the word educa?',\n",
       " 'output': 'There are 5 letters in the word \"educa\".'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can simplify this with AgentExecutor:\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"how many letters in the word educa?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThere are 5 letters in the word \"educa\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNo, \"educa\" is not a real word in English.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'is that a real word?',\n",
       " 'chat_history': [HumanMessage(content='how many letters in the word educa?'),\n",
       "  AIMessage(content='There are 5 letters in the word \"educa\".')],\n",
       " 'output': 'No, \"educa\" is not a real word in English.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are very powerful assistant, but bad at calculating lengths of words.\"),\n",
    "    MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# We can then set up a list to track the chat history\n",
    "\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "chat_history = []\n",
    "\n",
    "# We can then put it all together!\n",
    "\n",
    "agent = {\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x['intermediate_steps']),\n",
    "    \"chat_history\": lambda x: x[\"chat_history\"]\n",
    "} | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# When running, we now need to track the inputs and outputs as chat history\n",
    "\n",
    "input1 = \"how many letters in the word educa?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.append(HumanMessage(content=input1))\n",
    "chat_history.append(AIMessage(content=result['output']))\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
