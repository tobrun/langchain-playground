{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI Functions\n",
    "\n",
    "- How to use functions to get structured outputs from ChatOpenAI\n",
    "- How to create a generic chain that uses (multiple) functions\n",
    "- How to create a chain that actually executes the chosen function\n",
    "\n",
    "### Structured output\n",
    "We'll use `create_structured_output_chain` to create our chain, which takes the desired structured output either as a Pydantic class or as JsonSchema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for extracting information in structured formats.\n",
      "Human: Use the given format to extract information from the following input: Sally is 13\n",
      "Human: Tip: Make sure to answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Person(name='Sally', age=13, fav_food='Unknown')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic class\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Identifying information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The person's name\")\n",
    "    age: int = Field(..., description=\"The person's age\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The person's favorite food\")\n",
    "\n",
    "\n",
    "# If we pass in a model explicitly, we need to make sure it supports the OpenAI function-calling API.\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a world class algorithm for extracting information in structured formats.\"),\n",
    "        (\"human\", \"Use the given format to extract information from the following input: {input}\"),\n",
    "        (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = create_structured_output_chain(Person, llm, prompt, verbose=True)\n",
    "chain.run(\"Sally is 13\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can push the boundaries of his with having sequence of Persons matching a People class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for extracting information in structured formats.\n",
      "Human: Use the given format to extract information from the following input: Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.\n",
      "Human: Tip: Make sure to answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Sally', age=13, fav_food=''), Person(name='Joey', age=12, fav_food='spinach'), Person(name='Caroline', age=23, fav_food='')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: Sequence[Person] = Field(..., description=\"The people in the text\")\n",
    "\n",
    "\n",
    "chain = create_structured_output_chain(People, llm, prompt, verbose=True)\n",
    "chain.run(\n",
    "    \"Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using JSON schema\n",
    "\n",
    "Instead of using pydantic classes, you can leverage schema defintions instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for extracting information in structured formats.\n",
      "Human: Use the given format to extract information from the following input: Sally is 13\n",
      "Human: Tip: Make sure to answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Sally', 'age': 13}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"Person\",\n",
    "    \"description\": \"Identifying information about a person.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"title\": \"Name\", \"description\": \"The person's name\", \"type\": \"string\"},\n",
    "        \"age\": {\"title\": \"Age\", \"description\": \"The person's age\", \"type\": \"integer\"},\n",
    "        \"fav_food\": {\n",
    "            \"title\": \"Fav Food\",\n",
    "            \"description\": \"The person's favorite food\",\n",
    "            \"type\": \"string\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"],\n",
    "}\n",
    "\n",
    "chain = create_structured_output_chain(json_schema, llm, prompt, verbose=True)\n",
    "chain.run(\"Sally is 13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a generic OpenAI functions chain\n",
    "\n",
    "We can leverage `create_openai_fn_chain`. This is the same as `create_structured_output_chain`\n",
    "except that instead of taking a single output schema, it takes a sequence of function definitions.\n",
    "\n",
    "#### Pydantic classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for recording entities.\n",
      "Human: Make calls to the relevant function to record the entities in the following input: Harry was a chubby brown beagle who loved chicken\n",
      "Human: Tip: Make sure to answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecordDog(name='Harry', color='brown', fav_food='chicken')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RecordPerson(BaseModel):\n",
    "    \"\"\"Record some identifying information about a pe.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The person's name\")\n",
    "    age: int = Field(..., description=\"The person's age\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The person's favorite food\")\n",
    "\n",
    "\n",
    "class RecordDog(BaseModel):\n",
    "    \"\"\"Record some identifying information about a dog.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The dog's name\")\n",
    "    color: str = Field(..., description=\"The dog's color\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The dog's favorite food\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a world class algorithm for recording entities.\"),\n",
    "        (\"human\", \"Make calls to the relevant function to record the entities in the following input: {input}\"),\n",
    "        (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = create_openai_fn_chain([RecordPerson, RecordDog], llm, prompt, verbose=True)\n",
    "chain.run(\"Harry was a chubby brown beagle who loved chicken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Functions\n",
    "We can pass in functions as Pydantic classes, directly as OpenAI function dicts, or Python functions. To pass Python function in directly, we'll want to make sure our parameters have type hints, we have a docstring, and we use Google Python style docstrings to describe the parameters.\n",
    "\n",
    "NOTE: To use Python functions, make sure the function arguments are of primitive types (str, float, int, bool) or that they are Pydantic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for recording entities.\n",
      "Human: Make calls to the relevant function to record the entities in the following input: The most important thing to remember about Tommy, my 12 year old, is that he'll do anything for apple pie.\n",
      "Human: Tip: Make sure to answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Tommy', 'age': 12, 'fav_food': {'food': 'apple pie'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OptionalFavFood(BaseModel):\n",
    "    \"\"\"Either a food or null.\"\"\"\n",
    "\n",
    "    food: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Either the name of a food or null. Should be null if the food isn't known.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def record_person(name: str, age: int, fav_food: OptionalFavFood) -> str:\n",
    "    \"\"\"Record some basic identifying information about a person.\n",
    "\n",
    "    Args:\n",
    "        name: The person's name.\n",
    "        age: The person's age in years.\n",
    "        fav_food: An OptionalFavFood object that either contains the person's favorite food or a null value. Food should be null if it's not known.\n",
    "    \"\"\"\n",
    "    return f\"Recording person {name} of age {age} with favorite food {fav_food.food}!\"\n",
    "\n",
    "\n",
    "chain = create_openai_fn_chain([record_person], llm, prompt, verbose=True)\n",
    "chain.run(\n",
    "    \"The most important thing to remember about Tommy, my 12 year old, is that he'll do anything for apple pie.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass in multiple Python functions or OpenAI functions, then the returned output will be of the form:\n",
    "\n",
    "{\"name\": \"<<function_name>>\", \"arguments\": {<<function_arguments>>}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for recording entities.\n",
      "Human: Make calls to the relevant function to record the entities in the following input: I can't find my dog Henry anywhere, he's a small brown beagle. Could you send a message about him?\n",
      "Human: Tip: Make sure to answer in the correct format\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'record_dog',\n",
       " 'arguments': {'name': 'Henry', 'color': 'brown', 'fav_food': {'food': None}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def record_dog(name: str, color: str, fav_food: OptionalFavFood) -> str:\n",
    "    \"\"\"Record some basic identifying information about a dog.\n",
    "\n",
    "    Args:\n",
    "        name: The dog's name.\n",
    "        color: The dog's color.\n",
    "        fav_food: An OptionalFavFood object that either contains the dog's favorite food or a null value. Food should be null if it's not known.\n",
    "    \"\"\"\n",
    "    return f\"Recording dog {name} of color {color} with favorite food {fav_food}!\"\n",
    "\n",
    "\n",
    "chain = create_openai_fn_chain([record_person, record_dog], llm, prompt, verbose=True)\n",
    "chain.run(\n",
    "    \"I can't find my dog Henry anywhere, he's a small brown beagle. Could you send a message about him?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other chains using OpenAI functions\n",
    "\n",
    "- Extraction: information/entity extraction\n",
    "- Tagging: tag inputs\n",
    "- OpenAPI: take spec, execute request\n",
    "- QA with citations: extract citations from text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
